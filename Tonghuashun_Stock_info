import requests
import execjs
import pandas as pd
import time
from bs4 import BeautifulSoup

indexurl = ['http://data.10jqka.com.cn/hgt/hgtb/', 'http://data.10jqka.com.cn/hgt/sgtb/']


# 传入hgt/sgt的类型，循环的次数，和V参数，获取某一类别所有页数的数据，循环几次获得几页，返回text数据
def get_data(index, num, v):
    url = index + 'field/jlr/order/desc/ajax/1/page/' + num + '/'
    header = {
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',
        'Accept-Encoding': 'gzip, deflate', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive',
        'Host': 'data.10jqka.com.cn', 'Upgrade-Insecure-Requests': '1',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36',
        'Cookie': 'Hm_lvt_60bad21af9c824a4a0530d5dbf4357ca=1616155191; Hm_lpvt_60bad21af9c824a4a0530d5dbf4357ca=1616155191; Hm_lvt_78c58f01938e4d85eaf619eae71b4ed1=1616155191; Hm_lpvt_78c58f01938e4d85eaf619eae71b4ed1=1616155191; Hm_lvt_f79b64788a4e377c608617fba4c736e2=1616155191; Hm_lpvt_f79b64788a4e377c608617fba4c736e2=1616155191; v=' + v}
    print(url)
    response = requests.get(url, headers=header)
    # print(response.text)
    # print(response.status_code)
    return str(response.text)


# 传入hgt/sgt的url，和V参数，获得更新的时间
def get_time(index):
    header = {
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',
        'Accept-Encoding': 'gzip, deflate', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive',
        'Host': 'data.10jqka.com.cn', 'Upgrade-Insecure-Requests': '1',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36',
    }
    rawhtml = requests.get(index, headers=header).content
    soup = BeautifulSoup(rawhtml, 'html5lib')
    curtime = soup.select(".curtime .fr")[2].get_text()
    return str(curtime)


# 传入页面内容，形成dataframe，存储为csv文件
def get_csv(content, t):
    data = pd.DataFrame()
    data = data.append(pd.read_html(content), ignore_index=True)
    data['更新时间'] = t
    data.to_csv('data.csv', mode='a',
                header=['序号', '股票代码', '股票简称', '最新价', '涨跌额', '涨跌幅', '昨收', '今开', '最高', '最低', '资金净流入（元）', '成交量（手）',
                        '成交额（元）', '换手率（%）', '更新时间'], index=False)
    return data


def exe_js():
    with open('aes.min.js', 'r') as f:
        jscontent = f.read()
    context = execjs.compile(jscontent)
    # print(context)
    print(context.call("v"))
    return str(context.call("v"))


if __name__ == '__main__':
    flag = 0
    ctime = ['', '']
    updatetime = ['', '']
    while True:
        # pretime = ['', '']
        for n in range(0, 2):
            # pretime[n] = updatetime[n]
            ctime[n] = get_time(indexurl[n])
            resultlist = ''
            while flag < 2 or ctime[n] != updatetime[n]:
                flag = flag + 1
                for i in range(1, 100000):
                    v1 = exe_js()
                    result = get_data(indexurl[n], str(i), v1)
                    resultlist = resultlist + result
                    print('td出现的次数：', result.count('td'))
                    if int(result.count('td')) == 0:
                        break
                df = get_csv(resultlist, ctime[n])
                updatetime[n] = get_time(indexurl[n])
                if updatetime[n] == ctime[n]:
                    print('更新时间： ' + updatetime[n])
                    break
                else:
                    ctime[n] = updatetime[n]
        time.sleep(300)
